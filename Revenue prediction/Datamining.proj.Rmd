---
title: "Revenue Prediction model"
author: "Garima Sood"
date: "March 12, 2018"
output: html_document
---

```{r}
dataPath <- "C:/Users/garim/Documents/Quarter 2/Data Mining/Project/Merged data"
master_data <- read.csv(paste(dataPath,"master_data_with_imputed_budget_and_revenue.csv", sep = "/"))
summary(master_data)
```

**Data Processsing**

```{r}
master_data$release_date <- as.Date(master_data$release_date)

#To cut the impact of inflation on movie revenues & budgets, I am excluding data of movies released before Jan 1985

master_data <- master_data[master_data$release_date > as.Date("01/01/1985","%m/%d/%Y"),]
master_data <- master_data[master_data$budget > 0,]
master_data$actor_1_gender <- as.factor(ifelse(master_data$actor_1_gender==0,NA,ifelse(master_data$actor_1_gender==2,1,0)))
master_data$actor_2_gender <- as.factor(ifelse(master_data$actor_2_gender==0,NA,ifelse(master_data$actor_2_gender==2,1,0)))
master_data$actor_3_gender <- as.factor(ifelse(master_data$actor_3_gender==0,NA,ifelse(master_data$actor_3_gender==2,1,0)))
master_data$actor_4_gender <- as.factor(ifelse(master_data$actor_4_gender==0,NA,ifelse(master_data$actor_4_gender==2,1,0)))
master_data$actor_5_gender <- as.factor(ifelse(master_data$actor_5_gender==0,NA,ifelse(master_data$actor_5_gender==2,1,0)))
master_data$director_gender <- as.factor(ifelse(master_data$director_gender==0,NA,ifelse(master_data$director_gender==2,1,0)))
master_data$producer_gender <- as.factor(ifelse(master_data$producer_gender==0,NA,ifelse(master_data$producer_gender==2,1,0)))
master_data$collection <- as.factor(ifelse(nchar(as.character(master_data$belongs_to_collection))>0,1,0))

master_data$num_prod_comp <-(master_data$production_company_1!="")+(master_data$production_company_2!="")+
                            (master_data$production_company_3!="")

master_data$num_prod_ctry <-(master_data$production_country_1!="")+(master_data$production_country_2!="")+
                            (master_data$production_country_3!="")

master_data <- master_data[ , -which(names(master_data) %in% 
              c( "movie_id" ,"actor_1_name","actor_2_name","actor_3_name","actor_4_name","actor_5_name","director_name","producer_name",
                 "casting_gender","casting_name","belongs_to_collection","genre_2","genre_3","genre_4","production_company_1",
                 "production_company_2","production_company_3" ,"production_country_1", "production_country_2",  "production_country_3" , "spoken_language_1","spoken_language_2", "spoken_language_3" ,"homepage","imdb_id" ,"original_title","overview","poster_path", "status","title","video"))]

require(ggplot2)

p1<- ggplot(master_data, aes(x = actor_1_gender)) + geom_bar()
p2<- ggplot(master_data, aes(x = actor_2_gender)) + geom_bar()
p3<- ggplot(master_data, aes(x = actor_3_gender)) + geom_bar()
p4<- ggplot(master_data, aes(x = actor_4_gender)) + geom_bar()
p5<- ggplot(master_data, aes(x = actor_5_gender)) + geom_bar()
p6<- ggplot(master_data, aes(x = director_gender)) + geom_bar()
p7<- ggplot(master_data, aes(x = producer_gender)) + geom_bar()
p8<- ggplot(master_data, aes(x = budget)) + geom_histogram()
p9<- ggplot(master_data, aes(x = revenue)) + geom_histogram()
p10<-ggplot(master_data, aes(x = popularity)) + geom_histogram()
p11<-ggplot(master_data, aes(x = vote_average)) + geom_histogram()
p12<-ggplot(master_data, aes(x = vote_count)) + geom_histogram()

library(gridExtra)

grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12, nrow = 4, ncol=3)
```

Plots show that there are a lot of NA values in the different columns. Counting the NA values per column in the data

```{r}
perc_na <- function(x){
  return(sum(is.na(x))/length(x))
}

round(apply(master_data, 2, function(x) perc_na(x)),2)

master_data$na_count <- apply(master_data, 1, function(x) sum(is.na(x)))
table(master_data$na_count)
```

Deleting records with missing data in more than 9 columns, and checking the poportion of missing values in the updated data set

```{r}
data <- master_data[master_data$na_count<9,]
dim(data)

round(apply(data, 2, function(x) perc_na(x)),2)
```

After removing thee records, we are left with about 10% missing values in the gender column of lead actors, and 24% missing values in budget. Rest of the columns look good. 

Checking the distribution of our dependent variable (revenue)

```{r}
library(dplyr)
data$quartile <- ntile(data$revenue, 5)
size = as.matrix(table(data$quartile))
cbind(aggregate(data$revenue, by = list(data$quartile), mean), size)
ggplot(data, aes(x = revenue)) + geom_histogram()

```

Plot of budget & revenue
```{r}
plot(data$budget, data$revenue)
```

I see a few outliers. But first I will impute the missing values and then remove the outliers if needed. 

Missing value estimation:
```{r}
mean_impute <- function(x){
  a<- (mean(x[!is.na(x)]))
  x <- ifelse(is.na(x), a, x)
  return(x)
}

median_impute <-  function(x){
  a<- (median(x[!is.na(x)]))
  x <- ifelse(is.na(x), a, x)
  return(x)
}

mode_impute <-  function(x){
  ux <- (unique(x))
  a<-ux[which.max(tabulate(match(x[!is.na(x)], ux)))]
  x <- ifelse(is.na(x), a, x)
  return(x)
}

#Imputing missing values for gender (Actor 1 & 2) and budget. Dropping other columns with more than 15% missing values 

data.imp <- data[,-c(3,4,5,6,7)]

data.imp$actor_1_gender <- as.factor(mode_impute(data.imp$actor_1_gender))
data.imp$actor_2_gender <- as.factor(mode_impute(data.imp$actor_2_gender))
data.imp$runtime <- median_impute(data.imp$runtime)

perc_blank <- function(x){
  return(sum(x ==""|x==" ")/length(x))
}
round(apply(data.imp, 2, function(x) perc_blank(x)),2)

#data.forest <- data.imp[!is.na(data.imp$budget),]
#library(randomForest)

#rfor.impute <-randomForest(budget~ revenue + actor_1_gender+actor_2_gender+popularity +release_date + runtime +vote_average + vote_count 
#                           +collection+num_prod_comp, data = data.forest)
```

```{r}
#Impute the missing budget values: Not needed now

data.imp$budget[is.na(data.imp$budget)] <- predict(rfor.impute,data.imp[is.na(data.imp$budget),] )

plot(density(data.imp$budget),col="red")
lines(density(data.forest$budget),col="blue")
lines(density(median_impute(data$budget)),col="black")

hist(log(data.imp$budget))
```


```{r}
sd.budget <- sqrt(var(data.imp$budget))
sd.budget*6
length(data.imp$budget[data.imp$budget>2e+08])
data.final <-data.imp[,-which(names(data.imp) %in% c('na_count', 'genre_1', 'adult','tagline','original_language','release_date'))]
data.final$success <- ifelse(data.final$revenue>1.25*(data.final$budget),1,0)

#Splitting the data into test & train
c <- round(nrow(data.final)*0.7,0)
s <- sample(1:nrow(data.final), c)

train <- data.final[s,]
test <- data.final[-s,]
```

Building a model to predict revenue of the movie before it is released. I will not model the vote count and vote average variables as they are collected after the release of the movie.

Build a multiple linear model for revenue prediction

```{r}
par(mfrow = c(2,3))
for (i in c("budget","popularity","runtime", "vote_average", "vote_count")){
  plot(data.final$revenue, eval(parse(text = paste0("data.final$",i))), ylab = i)
}
```
Cleary vote count has an increasing relationship with revenue as that indicates # people who went to watch the movie

**Fitting a linear model**
```{r}

revenue_pred <- lm(revenue~ actor_1_gender+ actor_2_gender+ popularity+runtime+collection+num_prod_comp+num_prod_ctry + budget, data = train)
summary(revenue_pred)

#cor(predict(revenue_pred, test), test$revenue)

library(Metrics)

rmseTest <- rmse((predict(revenue_pred, test)),test$revenue)
rmseTrain <-rmse((predict(revenue_pred, train)),train$revenue)

#Validation
cbind(rmseTrain, rmseTest)
```


**Fitting a regression tree model**
```{r}
library(rpart)
library(rpart.plot)

revenue_tree <- rpart(revenue~ actor_1_gender+ actor_2_gender+ popularity+runtime+collection+num_prod_comp+num_prod_ctry + budget, data = train)

plotcp(revenue_tree)

# Retreive optimal cp value based on cross-validated error
opt_index <- which.min(revenue_tree$cptable[, "xerror"])
cp_opt <- revenue_tree$cptable[opt_index, "CP"]

revenue_tree_opt <- prune(tree = revenue_tree, 
                         cp = cp_opt)

# Display the pruned tree results
rpart.plot(x = revenue_tree_opt, yesno = 2, type = 1, extra = 1)
```

Looking at the accuracy and confusion matrix of from tree model (test vs. train)
```{r}

predictedTest <- predict(revenue_tree_opt, test)
rmseTest <- rmse((test$revenue),predictedTest)
rmseTrain <- rmse((train$revenue),predictedTrain)

r_sqTest <- 1-rmseTest^2/var(test$revenue)
r_sqTr <- 1-rmseTrain^2/var(train$revenue)

a<- round(rbind(cbind(rmseTrain, rmseTest), cbind(r_sqTr, r_sqTest)),2)
rownames(a)<- c("RMSE", "R-sq")
colnames(a)<- c("Train", "Test")
a

```

```{r}
library(randomForest)
rfor1 <- randomForest(revenue~ actor_1_gender+ actor_2_gender+ popularity+runtime+collection+num_prod_comp+num_prod_ctry + budget, data= train)
```

```{r}
names(rfor1)
rfor1
rmseTest <- rmse(predict(rfor1, test), test$revenue)
rmseTrain <- rmse(predict(rfor1, train), train$revenue)
Rsq_test <- 1-(rmseTest)^2/var(test$revenue)
R_sqTr <- 1-(rmseTrain)^2/var(train$revenue)

a<- round(rbind(cbind(rmseTrain, rmseTest), cbind(R_sqTr, Rsq_test)),2)
rownames(a)<- c("RMSE", "R-sq")
colnames(a)<- c("Train", "Test")
a

```

I see overfitting in this model. Let me set the node size to avoid this:
```{r}
(rfor1$importance)

rfor2 <- randomForest(revenue~ actor_1_gender+ popularity+runtime+collection+num_prod_comp+ budget, data= train, nodesize = 30)
rmseTest <- rmse(predict(rfor2, test), test$revenue)
rmseTrain <- rmse(predict(rfor2, train), train$revenue)
Rsq_test <- 1-(rmseTest)^2/var(test$revenue)
R_sqTr <- 1-(rmseTrain)^2/var(train$revenue)

a<- round(rbind(cbind(rmseTrain, rmseTest), cbind(R_sqTr, Rsq_test)),2)
rownames(a)<- c("RMSE", "R-sq")
colnames(a)<- c("Train", "Test")
a

```

**Performing cluster wise class regression**
```{r}

#clustreg function
clustreg=function(dat,k,tries,sed,niter){
  
  set.seed(sed)
  dat=as.data.frame(dat)
  rsq=rep(NA,niter)
  res=list()
  rsq.best=0
  for(l in 1:tries) {
    
    c = sample(1:k,nrow(dat),replace=TRUE)
    yhat=rep(NA,nrow(dat))
    for(i in 1:niter) {		
      resid=pred=matrix(0,nrow(dat),k)
      for(j in 1:k){	
        pred[,j]=predict(glm(dat[c==j,],family="gaussian"),newdata=dat)		
        resid[,j] = (pred[,j]-dat[,1])^2
      }
      
      c = apply(resid,1,which.min)
      for(m in 1:nrow(dat)) {yhat[m]=pred[m,c[m]]}
      rsq[i] = cor(dat[,1],yhat)^2	
      #print(rsq[i])
    }
    
    if(rsq[niter] > rsq.best) {	
      rsq.best=rsq[niter]
      l.best=l
      c.best=c
      yhat.best=yhat
    }
  }
  
  for(i in k:1) res[[i]]=summary(lm(dat[c.best==i,]))
  
  return(list(data=dat,nclust=k,tries=tries,seed=sed,rsq.best=rsq.best,number.loops=niter, Best.try=l.best,cluster=c.best,results=res))
}

rev_clust <- clustreg(train[,c(5,1,2,3,4,6,9,10,11)],5,100,881,50)
table(rev_clust$cluster)

rev_clust$results

```

```{r}
clustreg.predict=function(results,newdat){
  
  yhat=rep(NA,nrow(newdat))
  resid=pred=matrix(0,nrow(newdat),length(table(results$cluster)))
  
  for(j in 1:length(table(results$cluster))){			
    pred[,j]=predict(glm(results$data[results$cluster==j,],family="gaussian"),newdata=newdat)		
    resid[,j] = (pred[,j]-newdat[,1])^2
  }
  
  c = apply(resid,1,which.min)
  for(m in 1:nrow(newdat)) {yhat[m]=pred[m,c[m]]}
  rsq = cor(newdat[,1],yhat)^2	
  
  return(list(results=results,newdata=newdat,cluster=c,yhat=yhat,rsq=rsq))
  
}

testp <- clustreg.predict(rev_clust, test[,c(5,1,2,3,4,6,9,10,11)])

rmseTest <- rmse(testp$yhat , test$revenue)
rmseTrain <- rmse(clustreg.predict(rev_clust, train[,c(5,1,2,3,4,6,9,10,11)])$yhat, train$revenue)
Rsq_test <- 1-(rmseTest)^2/var(test$revenue)
R_sqTr <- 1-(rmseTrain)^2/var(train$revenue)

a<- round(rbind(cbind(rmseTrain, rmseTest), cbind(R_sqTr, Rsq_test)),2)
rownames(a)<- c("RMSE", "R-sq")
colnames(a)<- c("Train", "Test")
a

```
 
```{r}
train_clus <- as.data.frame(cbind(train, cluster = rev_clust$cluster))
cbind(aggregate(train_clus[,c(5,3,4,6,10,11)], by = list(train_clus$cluster), mean), size = table(train_clus$cluster))

colnames(train_clus)
```



```{r}
rev_clust4 <- clustreg(train[,c(5,1,2,3,4,6,9,10,11)],4,100,881,50)
table(rev_clust4$cluster)

rev_clust4$results

testp <- clustreg.predict(rev_clust4, test[,c(5,1,2,3,4,6,9,10,11)])

rmseTest <- rmse(testp$yhat , test$revenue)
rmseTrain <- rmse(clustreg.predict(rev_clust4, train[,c(5,1,2,3,4,6,9,10,11)])$yhat, train$revenue)
Rsq_test <- 1-(rmseTest)^2/var(test$revenue)
R_sqTr <- 1-(rmseTrain)^2/var(train$revenue)

a<- round(rbind(cbind(rmseTrain, rmseTest), cbind(R_sqTr, Rsq_test)),2)
rownames(a)<- c("RMSE", "R-sq")
colnames(a)<- c("Train", "Test")
a

train_clus4 <- as.data.frame(cbind(train, cluster = rev_clust4$cluster))
cbind(aggregate(train_clus4[,c(5,3,4,6,10,11)], by = list(train_clus4$cluster), mean), size = table(train_clus4$cluster))


```

```{r}
round(prop.table(table(train_clus4[,c(9)], train_clus4$cluster),1),2)

success_pred <- glm(success~ actor_1_gender+ actor_2_gender+popularity+runtime+collection+num_prod_comp+num_prod_ctry + budget, data = train, family = binomial(link = 'logit'))
summary(success_pred)

round(prop.table(table(actual = train$success,predicted = ifelse(predict(success_pred, train, type = 'response')>0.5,1,0)),1),2)
round(prop.table(table(actual = test$success,predicted = ifelse(predict(success_pred, test, type = 'response')>0.5,1,0)),1),2)

#table(actual = test$)

```

library(ggplot2)
library(GGally)

ggcorr(data_imp,angle = 0, nbreaks = 10,hjust = 1,size= 3.5,layout.exp = 1)


ggplot(data.final, aes(x = revenue, color = actor_1_gender)) + geom_density()

ggplot(data.final, aes(x = actor_1_gender, fill = revenue)) + geom_bar()
table( data.final$actor_1_gender)
par(mfrow = c(2,2))
for (i in c("actor_1_gender","actor_2_gender","collection", "num_prod_comp" ,"num_prod_ctry", "success")){
  barplot(eval(parse(text = paste0("data.final$",i))), data.final$revenue, xlab = i, )
}

